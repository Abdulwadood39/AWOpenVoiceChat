# TODO

Streaming everything (stt, tts, llm), if it'll help latency

Make it a pip package

Turn Taking model? Retell seems to be doing it.

OpenAI GPT API support

Web interface/API. Two websockets, audio in and audio out.

We don't have a good visualizer. And other UI is good.

Tortoise needs to be implemented properly.

Good demo videos showing interruptions and response time etc.

Integrations with popular LLM packages and software

[Silero](https://github.com/snakers4/silero-models) seems to work fast on cpu and has a lot of control over tts.

There should be a better way to import different things from stt and tts etc.
